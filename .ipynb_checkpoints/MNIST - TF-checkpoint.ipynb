{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Warning: Setting shuffle_files=True because split=TRAIN and shuffle_files=None. This behavior will be deprecated on 2019-08-06, at which point shuffle_files=False will be the default for all splits.\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running above line downloads the dataset on your machine in user->tensorflow_datasets. Parameter as_supervised loads data into two tuple structure [input, targets] useful for supervised learning. Parameter with_info provides metadata of data like version, features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating number of data points for validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_test_samples = 0.1 * mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling data to range between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = image / 255.\n",
    "    return image, label\n",
    "\n",
    "scaled_train_and_validation_data = mnist_train.map(scale)\n",
    "scaled_test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function map applies scale to every data point in mnist_train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling\n",
    "\n",
    "We want to shuffle because if we have groups of data in sequence(descending order) then our SGD batches may have one type of target dominating over others while optimizing. Uniform shuffling is being done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 10000 # When we have enormous we may not be able to shuffle in one operation hence buffer\n",
    "shuffled_train_validation_data = scaled_train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = shuffled_train_validation_data.take(num_validation_samples)\n",
    "train_data = shuffled_train_validation_data.skip(num_validation_samples)\n",
    "\n",
    "# Creating batches of 100 from train_data\n",
    "BATCH_SIZE = 100\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "validation_data = validation_data.batch(num_validation_samples) # no batching\n",
    "test_data = scaled_test_data.batch(num_test_samples) # no batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't need to batch validation set as we are not backpropogating during validation. Remember our weights will be adjusted only once per batch which in our case will happen after 100 samples and not after every sample. We do need to batch validation/test data hence we setting batch size as number of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs, validation_targets = next(iter(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_layer_size = 100\n",
    "output_size = 10\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28,28,1)),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(hidden_layer_size, activation='relu'),\n",
    "    tf.keras.layers.Dense(output_size, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "540/540 - 8s - loss: 0.3275 - accuracy: 0.9070 - val_loss: 0.1819 - val_accuracy: 0.9510\n",
      "Epoch 2/5\n",
      "540/540 - 8s - loss: 0.1374 - accuracy: 0.9589 - val_loss: 0.1322 - val_accuracy: 0.9637\n",
      "Epoch 3/5\n",
      "540/540 - 7s - loss: 0.0967 - accuracy: 0.9702 - val_loss: 0.1004 - val_accuracy: 0.9702\n",
      "Epoch 4/5\n",
      "540/540 - 7s - loss: 0.0731 - accuracy: 0.9781 - val_loss: 0.0834 - val_accuracy: 0.9773\n",
      "Epoch 5/5\n",
      "540/540 - 7s - loss: 0.0601 - accuracy: 0.9819 - val_loss: 0.0714 - val_accuracy: 0.9802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed000f40c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_EPOCHS = 5\n",
    "\n",
    "model.fit(train_data, epochs=NUM_EPOCHS, \n",
    "          validation_data=(validation_inputs, validation_targets),validation_steps=1, verbose=2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    540/Unknown - 7s 13ms/step - loss: 0.0462 - accuracy: 0.98610.0462475392881229 0.9861481\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(train_data)\n",
    "print(test_loss, test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our validation accuracy and test accuracy are similar we haven't overfit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting with individual image from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7133420e-05, 4.4041303e-06, 9.9902487e-01, 6.0444517e-04,\n",
       "        1.6176245e-06, 1.1704251e-07, 6.3686969e-07, 2.0527669e-04,\n",
       "        1.3879585e-04, 2.6991604e-06]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = next(iter(test_data))[0][1]\n",
    "model.predict([[img]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest value in above array is for index 2 which tells us that our prediction is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQeElEQVR4nO3dfbBU9X3H8fcnxEwqQQStBAE1WKzRpCUZoEyBSIzxgbGif8D4GFQypGOcNk5ae0enI9hq1Ckx1c7EQn3Ah2JiICM+TA2lrba1UtExCKI8DQiXW9AYIlZHBb79Y8/tXHD37L37dPbe3+c1s7N7z/ec3e/duZ97zp6H/SkiMLOB71NFN2BmreGwmyXCYTdLhMNulgiH3SwRDrtZIhz2AUrSv0n6dqOXlXSDpH+orzsrwqeLbsDySdoGfDsi/rnoXgAi4taie7DaeM1ulgiHvZ+SNEzSk5LekvTr7PHow2Y7WdJ/S/qNpMclDe+x/GRJz0vaK+mXkqb38nXnS3o4e/xZSQ9L+lX2PC9KGlFhuQ5JWyTtk/SapIt61E6W9C/Z87wt6RFJR/f9XbE8Dnv/9SngfuBE4ATgA+DvDpvnW8DVwPHAfuAuAEmjgKeAvwaGA38GLJP0233sYQ4wFBgDHAP8cdZHOVuAadn8C4CHJY3MagJ+kPX5xez55vexF6vCYe+nIuJXEbEsIt6PiH3ALcAZh832UESsi4j/Bf4SmC1pEHA58HREPB0RByNiJbAGmNHHNj6mFPLfiYgDEfFSRLxbod/HImJX9no/ATYBk7La5ohYGREfRsRbwA/L/C5WJ4e9n5J0pKS/l7Rd0rvAc8DRWZi77ejxeDtwBHAspa2BWdmm915Je4GpwEj65iHgGeBRSbsk3SHpiAr9fkvSKz1e70tZL0g6TtKjkjqz3+Xh7po1jsPef30f+F3gDyLiKOBr2XT1mGdMj8cnUFoTv03pn8BDEXF0j9vgiLitLw1ExMcRsSAiTgP+EDif0keHQ0g6EVgMXAscExFHA+t69PoDIIDfy36Xyw/7PawBHPb+4YhsZ1j37dPAEEqfj/dmO95uKrPc5ZJOk3QkcDPws4g4QGnN+UeSzpE0KHvO6WV28OWS9HVJX862Jt6l9M/kQJlZB1MK81vZcldRWrN3GwK8l/0uo4A/70sf1jsOe//wNKVgd9/mAz8CfovSmvoF4J/KLPcQ8ADwP8BngT8BiIgdwEzgBkoB3EEpYH39e/g88DNKQd8APEvpH8khIuI1YCHwX8Bu4MvAf/aYZQHwVeA3lHYcLu9jH9YL8pdXmKXBa3azRDjsZolw2M0S4bCbJaKlV71J8t5AsyaLiLLnKNS1Zpd0rqQ3JG2W1FHPc5lZc9V86C07kWIj8E1gJ/AicEl2TLXSMl6zmzVZM9bsk4DNEbE1Ij4CHqV0ooaZtaF6wj6KQy+02JlNO4SkeZLWSFpTx2uZWZ3q2UFXblPhE5vpEbEIWATejDcrUj1r9p0celXVaGBXfe2YWbPUE/YXgXGSviDpM8DFwIrGtGVmjVbzZnxE7Jd0LaUvLxgE3BcR6xvWmZk1VEuvevNndrPma8pJNWbWfzjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcJhN0tES4dstvZz6qmn5tbvueee3PoZZ5yRW9+6dWvF2qWXXpq77OrVq3Pr1jdes5slwmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmifAorgPc5MmTc+tPPfVUbn3YsGGNbOcQmzZtyq2feeaZufXOzs5GtjNgVBrFta6TaiRtA/YBB4D9ETGhnuczs+ZpxBl0X4+ItxvwPGbWRP7MbpaIesMewC8kvSRpXrkZJM2TtEbSmjpfy8zqUO9m/JSI2CXpOGClpNcj4rmeM0TEImAReAedWZHqWrNHxK7sfg/wc2BSI5oys8arOeySBksa0v0YOBtY16jGzKyxaj7OLmkspbU5lD4O/GNE3FJlGW/GN8FRRx1VsfbGG2/UvCzAsmXLcusLFy7MrV9wwQUVawsWLMhd9vXXX8+tT5qUvyH53nvv5dYHqoYfZ4+IrcDv19yRmbWUD72ZJcJhN0uEw26WCIfdLBEOu1ki/FXSA0BHR0fF2ogRI3KXveyyy3LrS5curamnbmvXrq1YGzt2bO6yV1xxRW796quvzq3fddddufXUeM1ulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXCXyU9AAwdOrRi7eyzz85ddsWKFbn1Dz/8sKaeGuH555/PrR9//PG59fHjx1es7d27t6ae+oNKl7h6zW6WCIfdLBEOu1kiHHazRDjsZolw2M0S4bCbJcLH2a1tzZ07N7e+ePHi3Pq4ceMq1rZs2VJTT/2Bj7ObJc5hN0uEw26WCIfdLBEOu1kiHHazRDjsZonw98Zb29q+fXvRLQwoVdfsku6TtEfSuh7ThktaKWlTdj+suW2aWb16sxn/AHDuYdM6gFURMQ5Ylf1sZm2satgj4jngncMmzwSWZI+XABc2uC8za7BaP7OPiIgugIjoknRcpRklzQPm1fg6ZtYgTd9BFxGLgEXgC2HMilTrobfdkkYCZPd7GteSmTVDrWFfAczJHs8BHm9MO2bWLFU34yUtBaYDx0raCdwE3Ab8VNJc4E1gVjObtDRNnjw5t17tu98/+OCDRrbT71UNe0RcUqH0jQb3YmZN5NNlzRLhsJslwmE3S4TDbpYIh90sEb7E1drWxIkTc+sbN27Mre/atauR7fR7XrObJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZonwcXYrzOmnn55bP++883Lr999/fyPbGfC8ZjdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEqGI1g3S4hFh0iOpYu3BBx/MXXbKlCm59WnTpuXWOzs7c+sDVUSUfdO9ZjdLhMNulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuHr2Qe4wYMH59YnTZpUV/3888/Pre/YsaNi7eKLL85dtqOjI7ee6nH0WlVds0u6T9IeSet6TJsvqVPSK9ltRnPbNLN69WYz/gHg3DLT74yI8dnt6ca2ZWaNVjXsEfEc8E4LejGzJqpnB921ktZmm/nDKs0kaZ6kNZLW1PFaZlanWsP+Y+BkYDzQBSysNGNELIqICRExocbXMrMGqCnsEbE7Ig5ExEFgMZC/y9bMCldT2CWN7PHjRcC6SvOaWXuoepxd0lJgOnCspJ3ATcB0SeOBALYB32lijwNe3jXfANOnT8+tz5o1q2Jtxoz8o6InnHBCbr1I48aNy60feeSRufX333+/ke30e1XDHhGXlJl8bxN6MbMm8umyZolw2M0S4bCbJcJhN0uEw26WCF/i2gauvPLK3Pq99zbv4Mf69evrWr7asMsHDx6sWOvq6spddu7cubn1oUOH5tZnz56dW0+N1+xmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSJ8nL0FTjnllNz6zTffXNfz5x0rv+qqq3KX3bx5c279sccey61XO85+5513VqzdeOONucted911ufXRo0fn1u1QXrObJcJhN0uEw26WCIfdLBEOu1kiHHazRDjsZolQRLTuxaTWvVgbefbZZ3Pr06ZNy62vWrUqtz5z5syKtUGDBuUue8cdd+TWq11rf+utt+bWb7/99oq1jz76KHdZq01ElP1ucq/ZzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEVD3OLmkM8CDweeAgsCgi/lbScOAnwEmUhm2eHRG/rvJcSR5nX716dW597NixufWpU6fm1js7OyvWql2Pfs455+TWn3jiidx63jF+K0Y9x9n3A9+PiC8Ck4HvSjoN6ABWRcQ4YFX2s5m1qaphj4iuiHg5e7wP2ACMAmYCS7LZlgAXNqtJM6tfnz6zSzoJ+AqwGhgREV1Q+ocAHNfo5syscXr9HXSSPgcsA74XEe9KZT8WlFtuHjCvtvbMrFF6tWaXdASloD8SEcuzybsljczqI4E95ZaNiEURMSEiJjSiYTOrTdWwq7QKvxfYEBE/7FFaAczJHs8BHm98e2bWKL3ZjJ8CXAG8KumVbNoNwG3ATyXNBd4EZjWnxfY3ZMiQ3Prw4cNz6ytXrsytDxs2LLd+9913V6ydddZZucuuWLEit37NNdfk1q3/qBr2iPgPoNIH9G80th0zaxafQWeWCIfdLBEOu1kiHHazRDjsZolw2M0S4a+SboFql7hOnDixruffv39/xdry5csr1gCuv/763Pqbb75ZU09WHH+VtFniHHazRDjsZolw2M0S4bCbJcJhN0uEw26WiF5/LZXV7plnnsmtjxkzJre+cePG3HpHR+Uv9n3hhRdyl7V0eM1ulgiH3SwRDrtZIhx2s0Q47GaJcNjNEuGwmyXC17ObDTC+nt0scQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S0TVsEsaI+lfJW2QtF7Sn2bT50vqlPRKdpvR/HbNrFZVT6qRNBIYGREvSxoCvARcCMwG3ouIv+n1i/mkGrOmq3RSTdVvqomILqAre7xP0gZgVGPbM7Nm69NndkknAV8BusczulbSWkn3SRpWYZl5ktZIWlNXp2ZWl16fGy/pc8CzwC0RsVzSCOBtIIC/orSpf3WV5/BmvFmTVdqM71XYJR0BPAk8ExE/LFM/CXgyIr5U5XkcdrMmq/lCGEkC7gU29Ax6tuOu20XAunqbNLPm6c3e+KnAvwOvAgezyTcAlwDjKW3GbwO+k+3My3sur9nNmqyuzfhGcdjNms/Xs5slzmE3S4TDbpYIh90sEQ67WSIcdrNEOOxmiXDYzRLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNEVP3CyQZ7G9je4+djs2ntqF17a9e+wL3VqpG9nVip0NLr2T/x4tKaiJhQWAM52rW3du0L3FutWtWbN+PNEuGwmyWi6LAvKvj187Rrb+3aF7i3WrWkt0I/s5tZ6xS9ZjezFnHYzRJRSNglnSvpDUmbJXUU0UMlkrZJejUbhrrQ8emyMfT2SFrXY9pwSSslbcruy46xV1BvbTGMd84w44W+d0UPf97yz+ySBgEbgW8CO4EXgUsi4rWWNlKBpG3AhIgo/AQMSV8D3gMe7B5aS9IdwDsRcVv2j3JYRPxFm/Q2nz4O492k3ioNM34lBb53jRz+vBZFrNknAZsjYmtEfAQ8CswsoI+2FxHPAe8cNnkmsCR7vITSH0vLVeitLUREV0S8nD3eB3QPM17oe5fTV0sUEfZRwI4eP++kvcZ7D+AXkl6SNK/oZsoY0T3MVnZ/XMH9HK7qMN6tdNgw423z3tUy/Hm9igh7uaFp2un435SI+CpwHvDdbHPVeufHwMmUxgDsAhYW2Uw2zPgy4HsR8W6RvfRUpq+WvG9FhH0nMKbHz6OBXQX0UVZE7Mru9wA/p/Sxo53s7h5BN7vfU3A//y8idkfEgYg4CCymwPcuG2Z8GfBIRCzPJhf+3pXrq1XvWxFhfxEYJ+kLkj4DXAysKKCPT5A0ONtxgqTBwNm031DUK4A52eM5wOMF9nKIdhnGu9Iw4xT83hU+/HlEtPwGzKC0R34LcGMRPVToayzwy+y2vujegKWUNus+prRFNBc4BlgFbMruh7dRbw9RGtp7LaVgjSyot6mUPhquBV7JbjOKfu9y+mrJ++bTZc0S4TPozBLhsJslwmE3S4TDbpYIh90sEQ67WSIcdrNE/B+UVTHEol9tfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pixels = np.array(img).reshape((28, 28))\n",
    "plt.title('Label is {label}'.format(label=\"aa\"))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the input image, we can see that image too is of digit 2 and our model was able to identify this successfully."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_3_TF_2.0",
   "language": "python",
   "name": "python_3_tf_2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
